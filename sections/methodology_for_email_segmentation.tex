
\chapter{Segmentation de courriels}

\label{ch:methodology_for_email_segmentation}

Nous présentons notre approche pour la segmentation de courriels ainsi que les traits utilisés pour l'apprentissage.

\section{Étiquetage de séquences}

Chaque courriel est traité comme une séquence de phrases. Nous choisissons de traiter le problème de la segmentation comme une tache d'étiquetage de séquences dont l'objectif est d'attribuer globalement le meilleur ensemble d'étiquettes pour la séquence entière d'un seul coup\footnote{Un exemple classique de tâche accomplie de cette manière est l'étiquetage morpho-syntaxique, qui cherche à identifier la nature grammaticale de chaque terme d'une phrase ou d'un document.}. L'idée sous-jacente est que l'étiquette la plus pertinente pour une phrase est dépendante des traits et de l'étiquette des phrases proches. Notre segmenteur est basé sur un classifieur utilisant les champs aléatoires de Markov, tel qu'implémenté dans le programme d'étiquetage de séquences \textit{Wapiti} \cite{lavergne2010practical}. Nous fixons la taille de la fenêtre à 5, c'est à dire que l'algorithme prend en compte non seulement les traits de la phrase qu'il cherche à étiqueter mais également ceux des deux phrases précédentes et des deux phrases suivantes.

Entraîner le classifieur à reconnaître les différents labels du schéma d'annotation précédemment déterminé peut être problématique. En effêt, il présente certains inconvénients qui peut nuire à l'efficacité du classifieur. En particulier, les phrases étiquetées \textit{SE} partageront, par définition, d'importantes caractéristiques avec les phrases étiquetées \textit{S} et \textit{E}. Nous choisissons donc de transformer ces annotations en un schéma binaire et nous contentons de différencier les phrases qui débutent un nouveau segment (\textit{True}), ou les "phrases-frontières", de celles qui ne débutent pas un nouveau segment (\textit{False}). Le processus de conversion est trivial, et peut facilement être inversé \footnote{Les phrases étiquetées \textit{SE} ou \textit{S} sont converties en \textit{True}, les autres en \textit{False}. Pour retrouver les étiquettes d'origine, un \textit{True} est changé en \textit{SE} si la phrase suivante est aussi une frontière (i.e. \textit{True})} et en \textit{S} dans le cas contraire. Un \textit{False} est changé en \textit{E} si la phrase suivante est une frontière (i.e. \textit{True}) et en \textit{I} dans le cas contraire.

\section{Ensembles de traits}

On distingue cinq ensembles de traits : les $n$-grammes, les traits basés sur la théorie de la structure de l'information, les traits thématiques, les traits stylistiques et les traits sémantiques (pour les expériences, les deux derniers ensembles sont regroupés sous l'appelation "traits divers"). Tous les traits sont indépendants du domaine et presque tous les traits sont indépendants du langage, à l'exception de certains (les traits sémantiques) qui peuvent être facilement traduits.

Pour construire les traits du segmenteur, nous utilisons l'étiqueteur de Stanford pour l'étiquetage morpho-syntaxique \cite{toutanova2003feature}, et la base de données lexicale \textit{WordNet} pour la lemmatisation \cite{miller1995wordnet}.

\subsection{$n$-grammes}

On sélectionne, de manière insensible à la casse, les 1000\footnote{Valeur estimée empiriquement.} bigrammes et les trigrammes avec la plus haut taux de présence dans les phrases du corpus (\textit{Document Frequency}). Puisque la probabilité d'avoir de multiples occurrences d'un même $n$-gramme dans une phrase est extrêmement faible, nous ne conservons pas le nombre d'occurrences mais une valeur booléenne pour ne considérer que la présence ou l'absence du $n$-gramme.

\subsection{Traits basés sur la théorie de la structure de l'information}

Cet ensemble de traits est inspuré de la théorie de la structure de l'information qui décrit l'information portée par une phrase en fonction de la façon dont elle est reliée à son contexte \cite{kruijff:1996}. La théorie lie ces fonctions avec des constructions syntaxiques particulières (e.g. thématisation) et des contraintes sur l'ordre des mots dans la phrase. En effet pour des langages comme l'anglais ou le français, le début de la phrase est une position importante pour structurer l'information au niveau du discours, tandis que la fin de la phrase peut comporter d el'information utile pour annoncer ce qui vient ensuite. 

On s'intéresse aux trois premiers et derniers tokens significatifs de la phrase. Un token est considéré comme significatif si sa fréquence est supérieure à 1/2 000\footnote{Cette valeur a été déterminée empiriquement par rapport à nos données. Un travail supplémentaire devra être effectué pour la généraliser.}. Si une phrase contient moins de six tokens significatifs, le même token peut se retrouver dans les deux triplets. Si la phrase contient moins de trois tokens significatifs, les valeurs manquantes sont remplacées par une valeur spéciale "bouche-trou". Nous définissons troits traits individuels pour chacun des trois unigrammes, les deux bigrammes et le trigramme qui se trouvent dans chacun de ces triplets. Les traits sont les suivants : la forme de surface de chaque token (sensible à la casse), leur forme lemmatisée (insensible à la casse) et leur étiquette morpho-syntaxique. Ces traits sont illustrés par la figure \ref{fig:exampleSyntacticFeatures}.

\subsection{Trait thématique}

Le seul trait que nous prenons en compte pour la reconnaissance des variations thématiques est la sortie de l'algorithme \textit{TextTiling} \cite{hearst1997texttiling}. \textit{TextTiling} est l'un des algorithmes les plus communément utilisés pour la segmentation automatique de texte. Si l'algorithme détecte une rupture dans la cohésion lexicale du text (entre deux blocs consécutifs), il place une frontière pour indiquer un changement thématique. En raison de la taille relativement courte des courriels, nous définissons la taille d'un bloc comme égale à trois fois la taille moyenne d'une phrase dans notre corpus. Nous définissons la "taille-étape" (la distance parcouru par la fenêtre glissante à chaque étape) comme égale à la taille moyenne d'une phrase du corpus.

\subsection{Traits divers}

Cet ensemble inclut les traits stylistiques et sémantiques. Il contient 24 traits, plusieurs ayant été empruntés à des travaux dans le domaine de la classification d'actes de dialogue \cite{qadir2011classifying} et de la segmentation de courriels \cite{lampert2009segmenting}. 

Les traits stylistiques capturent l'information portant sur la structure visuelle et la composition du message : 

\begin{itemize}
	\item[\bullet] la position de la phrase dans le courriel
	\item[\bullet] la taille moyenne de ses tokens
	\item[\bullet] le nombre total de tokens 
	\item[\bullet] le nombre total de caractères
	\item[\bullet] la proportion de majuscules
	\item[\bullet] la proportion de caractères alphabétiques
	\item[\bullet] la proportion de caractères numériques
	\item[\bullet] le nombre de chevrons
	\item[\bullet] si la phrase finit sur ou contient un point d'interrogation, une virgule ou un point-virgule
	\item[\bullet] si la phrase contient des caractères de ponctuation parmi ses trois premiers tokens (pour reconnaître les salutations \cite{qadir2011classifying}).
\end{itemize}

Les traits sémantiques cherchent à identifier certains mots et formules particuliers : 

\begin{itemize}
	\item[\bullet] si la phrase commence par un mot interrogatif de type "wh" (\textit{``who''}, \textit{``when''}, \textit{``where''}, \textit{``what''}, \textit{``which''}, \textit{``what''}, \textit{``how''})
	\item[\bullet] si la phrase contient un mot interrogatif de type "wh"
	\item[\bullet] si la phrase commence par une forme interrogative (e.g. "\textit{is it}", "\textit{are there}"...)
	\item[\bullet] si la phrase contient une forme interrogative
	\item[\bullet] si la phrase contient un modal (\textit{``can''}, \textit{``may''}, \textit{``must''}, \textit{``shall''}, \textit{``will''}, \textit{``might''}, \textit{``should''}, \textit{``would''}, \textit{``could''}, et leurs formes négatives)
	\item[\bullet] si la phrase contient une formule de planification (e.g. "\textit{I will}", "\textit{we are going to}"...)
	\item[\bullet] si la phrase contient des indices de la première personne (e.g. "\textit{we}", "\textit{my}"...)
	\item[\bullet] si la phrase contient des indices de la deuxième personne
	\item[\bullet] si la phrase contient des indices de la troisième personne
	\item[\bullet] le premier pronom personnel trouvé dans la phrase
	\item[\bullet] la première forme verbale rencontrée, telle qu'étiquetée par l'étiqueteur de Stanford, c'est à dire un élément du \textit{Penn Treebank tag set}\footnote{Liste alphabétique des étiquettes morpho-syntaxiques utilisées par le \textit{Penn Treebank Project} : \url{http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html}} (e.g. le trait \textit{``VBZ''} indique un verbe au présent et à la troisième personne du singulier).
\end{itemize}

\begin{table}\small\centering
	\begin{tabular}{*{2}{c}c}
		\toprule
		\textbf{Formes de surface} & \textbf{Lemmes} & \textbf{Étiquettes}\\
		\midrule
		Many & many & JJ\\
		thanks & thanks & NNS\\
		to & to & TO\\
		your & your & PRP\\
		suggestions & suggestion & DD\\
		. & . & .\\
		Many thanks & many thanks & JJ NNS\\
		thanks to . & thanks to . & NNS TO . \\
		your suggestions & your suggestion & PRP DD\\
		suggestions & suggestion & DD\\
		Many thanks to & many thanks to & JJ NNS TO\\
		your suggestions . & your suggestion . & PRP DD .\\
		\bottomrule
	\end{tabular}
	\caption{Traits syntaxiques formés par la phrase "\textit{Many thanks to all of you for the help you have offered, I have learned tremendously from all your suggestions}". Chaque cellule est un trait (36 au total).}
	\label{fig:exampleSyntacticFeatures}
\end{table}